网页下载器：将互联网上URL对应的网页下载到本地的工具

Python有哪几种网页下载器？
	-urllib2官方基本模块
	-request第三方模块
	
urllib2下载网页方法1：
	urllib2.urlopen(url)
*********************************	
	举例：
		import urllib2
			#直接请求
		response = urllib2.urlopen("http://www.baidu.com")
			#获取状态码，如果是200表示获取成功
		print response.getcode()
			#读取内容
		cont = response.read()
		
		
urllib2下载网页方法2：添加data、httpheader
	url,data,header传入urllib2.request,再用urllib2.urlopen(request)
*********************************
	举例：
		import urllib2
			#创建Request对象
		request = urllib2.Request(url)
			#添加数据
		request.add_data('a','1')
			#添加http的header
		request.add_header('User-Agent','Mozilla/5.0')
			#发送请求，获取结果
		response = urllib2.urlopen(requset)
		
		
urllib2下载网页方法3：添加特殊情景的处理器
	-cookie处理：HTTPCookieProcessor
	-代理：ProxyHandler
	-协议：HTTPSHandler
	-HTTPRedirectHandler
#创建open对象
opener = urllib2.build_opener(handler)
#安装对象
urllib2.install_opener(opener)
#安装后调用传统方法
urllib2.urlopen(url)
urllib2.urlopen(request)
*********************************
	举例：	
	import urllib2, cookielib
		#创建cookie容器
	cj = cookielib.CookieJar()
		#创建一个opener
	opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))
		#给urllib2安装opener
	urllib2.install_opener(opener)
		#使用带有cookie的urllib2访问网址
	response = urllib2.urlopen("http://www.baidu.com")
	
	
		
		